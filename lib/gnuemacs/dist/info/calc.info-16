Info file: calc.info,    -*-Text-*-
produced by texinfo-format-buffer
from file: calc.texinfo





This file documents Calc, the GNU Emacs calculator.

Copyright (C) 1990, 1991 Free Software Foundation, Inc.

Permission is granted to make and distribute verbatim copies of this
manual provided the copyright notice and this permission notice are
preserved on all copies.

Permission is granted to copy and distribute modified versions of this
manual under the conditions for verbatim copying, provided also that the
section entitled "GNU General Public License" is included exactly as
in the original, and provided that the entire resulting derived work is
distributed under the terms of a permission notice identical to this one.

Permission is granted to copy and distribute translations of this manual
into another language, under the above conditions for modified versions,
except that the section entitled "GNU General Public License" may be
included in a translation approved by the author instead of in the
original English.



File: calc.info  Node: Numerical Solutions, Prev: Solving Equations, Up: Algebra, Next: Curve Fitting

Numerical Solutions
===================

Not all equations can be solved symbolically.  The commands in this
section use numerical algorithms that can find a solution to a specific
instance of an equation to any desired accuracy.  Note that these
commands are slower than their algebraic cousins; it is a good idea
to try `a S' before resorting to `a R'.

(*Note Curve Fitting::, for some other, more specialized, operations
on numerical data.)

* Menu:

* Root Finding::
* Minimization::
* Numerical Systems of Equations::


File: calc.info  Node: Root Finding, Prev: Numerical Solutions, Up: Numerical Solutions, Next: Minimization

Root Finding
------------

The `a R' (`calc-find-root') [`root'] command finds a
numerical solution (or "root") of an equation.  (This command treats
inequalities the same as equations.  If the input is any other kind
of formula, it is interpreted as an equation of the form `X = 0'.)

The `a R' command requires an initial guess on the top of the
stack, and a formula in the second-to-top position.  It prompts for a
solution variable, which must appear in the formula.  All other variables
that appear in the formula must have assigned values, i.e., when
a value is assigned to the solution variable and the formula is
evaluated with `=', it should evaluate to a number.  Any assigned
value for the solution variable itself is ignored and unaffected by
this command.

When the command completes, the initial guess is replaced on the stack
by a vector of two numbers:  The value of the solution variable that
solves the equation, and the difference between the lefthand and
righthand sides of the equation at that value.  Ordinarily, the second
number will be zero or very nearly zero.  (Note that Calc uses a
slightly higher precision while finding the root, and thus the second
number may be slightly different from the value you would compute from
the equation yourself.)

The `v h' (`calc-head') command is a handy way to extract
the first element of the result vector, discarding the error term.

The initial guess can be a real number, in which case Calc searches
for a real solution near that number, or a complex number, in which
case Calc searches the whole complex plane near that number for a
solution, or it can be an interval form which restricts the search
to real numbers inside that interval.

Calc tries to use `a d' to take the derivative of the equation.
If this succeeds, it uses Newton's method.  If the equation is not
differentiable Calc uses a bisection method.  (If Newton's method
appears to be going astray, Calc switches over to bisection if it
can, or otherwise gives up.  In this case it may help to try again
with a slightly different initial guess.)  If the initial guess is a
complex number, the function must be differentiable.

If the formula (or the difference between the sides of an equation)
is negative at one end of the interval you specify and positive at
the other end, the root finder is guaranteed to find a root.
Otherwise, Calc subdivides the interval into small parts looking for
positive and negative values to bracket the root.  When your guess is
an interval, Calc will not look outside that interval for a root.

The `H a R' [`wroot'] command is similar to `a R', except
that if the initial guess is an interval for which the function has
the same sign at both ends, then rather than subdividing the interval
Calc attempts to widen it to enclose a root.  Use this mode if
you are not sure if the function has a root in your interval.

If the function is not differentiable, and you give a simple number
instead of an interval as your initial guess, Calc uses this widening
process even if you did not type the Hyperbolic flag.  (If the function
*is* differentiable, Calc uses Newton's method which does not
require a bounding interval in order to work.)

If Calc leaves the `root' or `wroot' function in symbolic
form on the stack, it will normally display an explanation for why
no root was found.  If you miss this explanation, press `w'
(`calc-why') to get it back.


File: calc.info  Node: Minimization, Prev: Root Finding, Up: Numerical Solutions, Next: Numerical Systems of Equations

Minimization
------------

The `a N' (`calc-find-minimum') [`minimize'] command
finds a minimum value for a formula.  It is very similar in operation
to `a R' (`calc-find-root'):  You give the formula and an initial
guess on the stack, and are prompted for the name of a variable.  The guess
may be either a number near the desired minimum, or an interval enclosing
the desired minimum.  The function returns a vector containing the
value of the the variable which minimizes the formula's value, along
with the minimum value itself.

Note that this command looks for a *local* minimum.  Many functions
have more than one minimum; some, like `x sin(x)', have infinitely
many.  In fact, there is no easy way to define the "global" minimum
of `x sin(x)' but Calc can still locate any particular local minimum
for you.  Calc basically goes downhill from the initial guess until it
finds a point at which the function's value is greater both to the left
and to the right.  Calc does not use derivatives when minimizing a function.

If your initial guess is an interval and it looks like the minimum
occurs at one or the other endpoint of the interval, Calc will return
that endpoint only if that endpoint is closed; thus, minimizing `17 x'
over `[2..3]' will return `[2, 38]', but minimizing over
`(2..3]' would report no minimum found.

Most functions are smooth and flat near their minimum values.  Because
of this flatness, if the current precision is, say, 12 digits, the
variable can only be determined meaningfully to about six digits.  Thus
you should set the precision to twice as many digits as you need in your
answer.

The `H a N' [`wminimize'] command, analogously to `H a R',
expands the guess interval to enclose a minimum rather than requiring
that the minimum lie inside the interval you supply.

The `a X' (`calc-find-maximum') [`maximize'] and
`H a X' [`wmaximize'] commands effectively minimize the
negative of the formula you supply.

The formula must evaluate to a real number at all points inside the
interval (or near the initial guess if the guess is a number).  If
the initial guess is a complex number the variable will be minimized
over the complex numbers; if it is real or an interval it will
be minimized over the reals.


File: calc.info  Node: Numerical Systems of Equations, Prev: Minimization, Up: Numerical Solutions

Systems of Equations
--------------------

The `a R' command can also solve systems of equations.  In this
case, the equation should instead be a vector of equations, the
guess should instead be a vector of numbers (intervals are not
supported), and the variable should be a vector of variables.  You
can omit the brackets while entering the list of variables.  Each
equation must be differentiable by each variable for this mode to
work.  The result will be a vector of two vectors:  The variable
values that solved the system of equations, and the differences
between the sides of the equations with those variable values.
There must be the same number of equations as variables.  Since
only plain numbers are allowed as guesses, the Hyperbolic flag has
no effect when solving a system of equations.

It is also possible to minimize over many variables with `a N'
(or maximize with `a X').  Once again the variable name should
be replaced by a vector of variables, and the initial guess should
be an equal-sized vector of initial guesses.  But, unlike the case of
multidimensional root finding, the formula being minimized should
still be a single formula, *not* a vector.  Beware that
multidimensional minimization is currently *very* slow.


File: calc.info  Node: Curve Fitting, Prev: Numerical Solutions, Up: Algebra, Next: Summations

Curve Fitting
=============

The `a F' command fits a set of data to a "model formula",
such as `y = m x + b' where `m' and `b' are parameters
to be determined.  For a typical set of measured data there will be
no single `m' and `b' that exactly fit the data; in this
case, Calc chooses values of the parameters that provide the closest
possible fit.

* Menu:

* Linear Fits::
* Polynomial and Multilinear Fits::
* Error Estimates for Fits::
* Standard Nonlinear Models::
* Curve Fitting Details::
* Interpolation::


File: calc.info  Node: Linear Fits, Prev: Curve Fitting, Up: Curve Fitting, Next: Polynomial and Multilinear Fits

Linear Fits
-----------

The `a F' (`calc-curve-fit') [`fit'] command attempts
to fit a set of data (`x' and `y' vectors of numbers) to a
straight line, polynomial, or other function of `x'.  For the
moment we will consider only the case of fitting to a line, and we
will ignore the issue of whether or not the model was in fact a good
fit for the data.

In a standard linear least-squares fit, we have a set of `(x,y)'
data points that we wish to fit to the "model" `y = m x + b'
by adjusting the parameters `m' and `b' to make the calculated
`y' values from the formula as close as possible to the actual
`y' values from the data set.  (In a polynomial fit, the model is
instead, say, `y = a x^3 + b x^2 + c x + d'.  In a multilinear fit,
we have data points of the form `(x1,x2,x3,y)' and our model is
`y = a x1 + b x2 + c x3 + d'.  These will be discussed later.)

In the model formula, variables like `x' and `x2' are called
the "independent variables", and `y' is the "dependent
variable".  Variables like `m', `a', and `b' are called
the "parameters" of the model.

The `a F' command takes the data set to be fitted from the stack.
By default, it expects the data in the form of a matrix.  For example,
for a linear or polynomial fit, this would be a 2xN matrix where
the first row is a list of `x' values and the second row has the
corresponding `y' values.  For the multilinear fit shown above,
the matrix would have four rows (`x1', `x2', `x3', and
`y', respectively).

If you happen to have an Nx2 matrix instead of a 2xN matrix,
just press `v t' first to transpose the matrix.

After you type `a F', Calc prompts you to select a model.  For a
linear fit, press the digit `1'.

Calc then prompts for you to name the variables.  By default it chooses
high letters like `x' and `y' for independent variables and
low letters like `a' and `b' for parameters.  (The dependent
variable doesn't need a name.)  The two kinds of variables are separated
by a semicolon.  Since you generally care more about the names of the
independent variables than of the parameters, Calc also allows you to
name only them and let the parameters use default names.

For example, suppose the data matrix

     [ [ 1, 2, 3, 4,  5  ]
       [ 5, 7, 9, 11, 13 ] ]

is on the stack and we wish to do a simple linear fit.  Type
`a F', then `1' for the model, then `RET' to use
the default names.  The result will be the formula `3 + 2 x'
on the stack.  Calc has created the model expression `a + b x',
then found the optimal values of `a' and `b' to fit the
data.  (In this case, it was able to find an exact fit.)  Calc then
substituted those values for `a' and `b' in the model.

The `a F' command puts two entries in the trail.  One is, as
always, a copy of the result that went to the stack; the other is
a vector of the actual parameter values, written as equations:
`[a = 3, b = 2]', in case you'd rather read them from a
vector than pick them out of the formula.  (You can type `t y'
to move this vector to the stack; *Note Trail Commands::.)

Specifying a different independent variable name will affect the
resulting formula: `a F 1 k RET' produces `3 + 2 k'.
Changing the parameter names (`a F 1 k;b,m RET') will affect
the equations that go into the trail.


To see what happens when the fit is not exact, we could change
the number 13 in the data matrix to 14 and try the fit again.
The result is:

     2.6 + 2.2 x

Evaluating this formula, say with `v x 5 RET TAB V M $ RET', shows
a reasonably close match to the y-values in the data.

     [4.8, 7., 9.2, 11.4, 13.6]

Since there is no line which passes through all the N data points,
Calc has chosen a line that best approximates the data points using
the method of least squares.  The idea is to define the "chi-square"
error measure

     chi^2 = sum((y_i - (a + b x_i))^2, i, 1, N)

which is clearly zero if `a + b x' exactly fits all data points,
and increases as various `a + b x_i' values fail to match the
corresponding `y_i' values.  There are several reasons why the
summand is squared, one of them being to ensure that `chi^2 >= 0'.
Least-squares fitting simply chooses the values of `a' and `b'
for which the error `chi^2' is as small as possible.

Other kinds of models do the same thing but with a different model
formula in place of `a + b x_i'.


A numeric prefix argument causes the `a F' command to take the
data in some other form than one big matrix.  A positive argument N
will take N items from the stack, corresponding to the N rows
of a data matrix.  In the linear case, N must be 2 since there
is always one independent variable and one dependent variable.

A prefix of zero or plain `C-u' is a compromise; Calc takes two
items from the stack, an N-row matrix of `x' values, and a
vector of `y' values.  If there is only one independent variable,
the `x' values can be either a one-row matrix or a plain vector,
in which case the `C-u' prefix is the same as a `C-u 2' prefix.


File: calc.info  Node: Polynomial and Multilinear Fits, Prev: Linear Fits, Up: Curve Fitting, Next: Error Estimates for Fits

Polynomial and Multilinear Fits
-------------------------------

To fit the data to higher-order polynomials, just type one of the
digits `2' through `9' when prompted for a model.  For example,
we could fit the original data matrix from the previous section
(with 13, not 14) to a parabola instead of a line by typing
`a F 2 RET'.

     2.00000000001 x - 1.5e-12 x^2 + 2.99999999999

Note that since the constant and linear terms are enough to fit the
data exactly, it's no surprise that Calc chose a tiny contribution
for `x^2'.  (The fact that it's not exactly zero is due only
to roundoff error.  Since our data are exact integers, we could get
an exact answer by typing `m f' first to get fraction mode.
Then the `x^2' term would vanish altogether.  Usually, though,
the data being fitted will be approximate floats so fraction mode
won't help.)

Doing the `a F 2' fit on the data set with 14 instead of 13
gives a much larger `x^2' contribution, as Calc bends the
line slightly to improve the fit.

     0.142857142855 x^2 + 1.34285714287 x + 3.59999999998

An important result from the theory of polynomial fitting is that it
is always possible to fit N data points exactly using a polynomial
of degree N-1, sometimes called an "interpolating polynomial".
Using the modified (14) data matrix, a model number of 4 gives
a polynomial that exactly matches all five data points:

     0.04167 x^4 - 0.4167 x^3 + 1.458 x^2 - 0.08333 x + 4.

The actual coefficients we get with a precision of 12, like
`0.0416666663588', clearly suffer from loss of precision.
It is a good idea to increase the working precision to several
digits beyond what you need when you do a fitting operation.
Or, if your data are exact, use fraction mode to get exact
results.

You can type `i' instead of a digit at the model prompt to fit
the data exactly to a polynomial.  This just counts the number of
columns of the data matrix to choose the degree of the polynomial
automatically.

Fitting data "exactly" to high-degree polynomials is not always
a good idea, though.  High-degree polynomials have a tendency to
wiggle uncontrollably in between the fitting data points.  Also,
if the exact-fit polynomial is going to be used to interpolate or
extrapolate the data, it is numerically better to use the `a p'
command described below.  *Note Interpolation::.


Another generalization of the linear model is to assume the
`y' values are a sum of linear contributions from several
`x' values.  This is a "multilinear" fit, and it is also
selected by the `1' digit key.  (Calc decides whether the fit
is linear or multilinear by counting the rows in the data matrix.)

Given the data matrix,

     [ [  1,   2,   3,    4,   5  ]
       [  7,   2,   3,    5,   2  ]
       [ 14.5, 15, 18.5, 22.5, 24 ] ]

the command `a F 1 RET' will call the first row `x' and the
second row `y', and will fit the values in the third row to the
model `a + b x + c y'.

     8. + 3. x + 0.5 y

Calc can do multilinear fits with any number of independent variables
(i.e., with any number of data rows).


Yet another variation is "homogeneous" linear models, in which
the constant term is known to be zero.  In the linear case, this
means the model formula is simply `a x'; in the multilinear
case, the model might be `a x + b y + c z'; and in the polynomial
case, the model could be `a x + b x^2 + c x^3'.  You can get
a homogeneous linear or multilinear model by pressing the letter
`h' followed by a regular model key, like `1' or `2'.

It is certainly possible to have other constrained linear models,
like `2.3 + a x' or `a - 4 x'.  While there is no single
key to select models like these, a later section shows how to enter
any desired model by hand.  In the first case, for example, you
would enter `a F ' 2.3 + a x'.

Another class of models that will work but must be entered by hand
are multinomial fits, e.g., `a + b x + c y + d x^2 + e y^2 + f x y'.


File: calc.info  Node: Error Estimates for Fits, Prev: Polynomial and Multilinear Fits, Up: Curve Fitting, Next: Standard Nonlinear Models

Error Estimates for Fits
------------------------

With the Hyperbolic flag, `H a F' [`efit'] performs the same
fitting operation as `a F', but reports the coefficients as error
forms instead of plain numbers.  Fitting our two data matrices (first
with 13, then with 14) to a line with `H a F' gives the results,

     3. + 2. x
     2.6 +/- 0.382970843103 + 2.2 +/- 0.115470053838 x

In the first case the estimated errors are zero because the linear
fit is perfect.  In the second case, the errors are nonzero but
moderately small, because the data are still very close to linear.

It is also possible for the *input* to a fitting operation to
contain error forms.  The data values must either all include errors
or all be plain numbers.  Error forms can go anywhere but generally
go on the numbers in the last row of the data matrix.  If the last
row contains error forms
`y_i +/- sigma_i', then the `chi^2'
statistic is now,

     chi^2 = sum(((y_i - (a + b x_i)) / sigma_i)^2, i, 1, N)

so that data points with larger error estimates contribute less to
the fitting operation.

If there are error forms on other rows of the data matrix, all the
errors for a given data point are combined; the square root of the
sum of the squares of the errors forms the `sigma_i' used for
the data point.

Both `a F' and `H a F' can accept error forms in the input
matrix, although if you are concerned about error analysis you will
probably use `H a F' so that the output also contains error
estimates.

If the input contains error forms but all the `sigma_i' values are
the same, it is easy to see that the resulting fitted model will be
the same as if the input did not have error forms at all (`chi^2'
is simply scaled uniformly by `1 / sigma^2', which doesn't affect
where it has a minimum).  But there *will* be a difference
in the estimated errors of the coefficients reported by `H a F'.

Consult any text on statistical modelling of data for a discussion
of where these error estimates come from and how they should be
interpreted.


With the Inverse flag, `I a F' [`xfit'] produces even more
information.  The result is a vector of six items:

  1. The model formula with error forms for its coefficients or
     parameters.  This is the result that `H a F' would have
     produced.

  2. A vector of "raw" parameter values for the model.  These are the
     polynomial coefficients or other parameters as plain numbers, in the
     same order as the parameters appeared in the final prompt of the
     `I a F' command.  For polynomials of degree `d', this vector
     will have length `M = d+1' with the constant term first.

  3. The covariance matrix `C' computed from the fit.  This is
     an MxM symmetric matrix; the diagonal elements
     `C_j_j' are the variances `sigma_j^2' of the parameters.
     The other elements are covariances `sigma_i_j^2' that describe the
     correlation between pairs of parameters.  (A related set of
     numbers, the "linear correlation coefficients" `r_i_j',
     are defined as `sigma_i_j^2 / sigma_i sigma_j'.)

  4. A vector of `M' "parameter filter" functions whose
     meanings are described below.  If no filters are necessary this
     will instead be an empty vector; this is always the case for the
     polynomial and multilinear fits described so far.

  5. The value of `chi^2' for the fit, calculated by the formulas
     shown above.  This gives a measure of the quality of the fit;
     statisticians consider `chi^2 = N - M' to indicate a moderately good fit
     (where again `N' is the number of data points and `M'
     is the number of parameters).

  6. A measure of goodness of fit expressed as a probability `Q'.
     This is computed from the `utpc' probability distribution
     function using `chi^2' with `N - M' degrees of freedom.  A
     value of 0.5 implies a good fit; some texts recommend that often
     `Q = 0.1' or even 0.001 can signify an acceptable fit.  In
     particular, `chi^2' statistics assume the errors in your inputs
     follow a normal (Gaussian) distribution; if they don't, you may
     have to accept smaller values of `Q'.

     The `Q' value is computed only if the input included error
     estimates.  Otherwise, Calc will report the symbol `nan'
     for `Q'.  The reason is that in this case the `chi^2'
     value has effectively been used to estimate the original errors
     in the input, and thus there is no redundant information left
     over to use for a confidence test.


File: calc.info  Node: Standard Nonlinear Models, Prev: Error Estimates for Fits, Up: Curve Fitting, Next: Curve Fitting Details

Standard Nonlinear Models
-------------------------

The `a F' command also accepts other kinds of models besides
lines and polynomials.  Some common models have quick single-key
abbreviations; others must be entered by hand as algebraic formulas.

Here is a complete list of the standard models recognized by `a F':

`1'
     Linear or multilinear.  a + b x + c y + d z.
`2-9'
     Polynomials.  a + b x + c x^2 + d x^3.
`e'
     Exponential.  a exp(b x) exp(c y).
`E'
     Base-10 exponential.  a 10^(b x) 10^(c y).
`x'
     Exponential (alternate notation).  exp(a + b x + c y).
`X'
     Base-10 exponential (alternate).  10^(a + b x + c y).
`l'
     Logarithmic.  a + b ln(x) + c ln(y).
`L'
     Base-10 logarithmic.  a + b log10(x) + c log10(y).
`^'
     General exponential.  a b^x c^y.
`p'
     Power law.  a x^b y^c.
`q'
     Quadratic.  a + b (x-c)^2 + d (x-e)^2.
`g'
     Gaussian.  (a / b sqrt(2 pi)) exp(-0.5*((x-c)/b)^2).

All of these models are used in the usual way; just press the appropriate
letter at the model prompt, and choose variable names if you wish.  The
result will be a formula as shown in the above table, with the best-fit
values of the parameters substituted.  (You may find it easier to read
the parameter values from the vector that is placed in the trail.)

All models except Gaussian can generalize as shown to any number of
independent variables.  Also, all the built-in models have an additive
or multiplicative parameter shown as `a' in the above table
which can be replaced by zero or one, as appropriate, by typing `h'
before the model key.

Note that many of these models are essentially equivalent, but express
the parameters slightly differently.  For example, `a b^x' and
the other two exponential models are all algebraic rearrangements of
each other.  Also, the "quadratic" model is just a degree-2 polynomial
with the parameters expressed differently.  Use whichever form best
matches the problem.

The HP-28/48 calculators support four different models for curve
fitting, called `LIN', `LOG', `EXP', and `PWR'.
These correspond to Calc models `a + b x', `a + b ln(x)',
`a exp(b x)', and `a x^b', respectively.  In each case,
`a' is what the HP-48 identifies as the "intercept," and
`b' is what it calls the "slope."


If the model you want doesn't appear on this list, press `''
(the apostrophe key) at the model prompt to enter any algebraic
formula, such as `m x - b', as the model.  (Not all models
will work, though---see the next section for details.)

The model can also be an equation like `y = m x + b'.
In this case, Calc thinks of all the rows of the data matrix on
equal terms; this model effectively has two parameters
(`m' and `b') and two independent variables (`x'
and `y'), with no "dependent" variables.  Model equations
do not need to take this `y =' form.  For example, the
implicit line equation `a x + b y = 1' works fine as a
model.

When you enter a model, Calc makes an alphabetical list of all
the variables that appear in the model.  These are used for the
default parameters, independent variables, and dependent variable
(in that order).  If you enter a plain formula (not an equation),
Calc assumes the dependent variable does not appear in the formula
and thus does not need a name.

For example, if the model formula has the variables `a,mu,sigma,t,x',
and the data matrix has three rows (meaning two independent variables),
Calc will use `a,mu,sigma' as the default parameters, and the
data rows will be named `t' and `x', respectively.  If you
enter an equation instead of a plain formula, Calc will use `a,mu'
as the parameters, `sigma,t' as the independent variables, and
`x' as the dependent variable (so that `sigma,t,x' stand for
the three rows of the data matrix).

You can, of course, override these choices by entering something
different at the prompt.  If you leave some variables out of the list,
those variables must have stored values and those stored values will
be used as constants in the model.  (Stored values for the parameters
and independent variables are ignored by the `a F' command.)
If you list only independent variables, all the remaining variables
in the model formula will become parameters.

If there are `$' signs in the model you type, they will stand
for parameters and all other variables (in alphabetical order)
will be independent.  Use `$' for one parameter, `$$' for
another, and so on.  Thus `$ x + $$' is another way to describe
a linear model.

If you type a `$' instead of `'' at the model prompt itself,
Calc will take the model formula from the stack.  (The data must then
appear at the second stack level.)  The same conventions are used to
choose which variables in the formula are independent by default and
which are parameters.

Models taken from the stack can also be expressed as vectors of two or
three elements, `[MODEL, VARS]' or `[MODEL, VARS, PARAMS]'.  Each of
VARS and PARAMS may be either variables or vectors of variables.  (If
PARAMS is omitted, all variables in MODEL except those listed as VARS
are parameters.)

When you enter a model manually with `'', Calc puts a 3-vector
describing the model in the trail so you can get it back if you wish.


Finally, you can store a model in one of the Calc variables
`Model1' or `Model2', then use this model by typing
`a F u' or `a F U' (respectively).  The value stored in
the variable can be any of the formats that `a F $' would
accept for a model on the stack.


Calc uses the principal values of inverse functions like `ln'
and `arcsin' when doing fits.  For example, when you enter
the model `y = sin(a t + b)' Calc actually uses the easier
form `arcsin(y) = a t + b'.  The `arcsin' function always
returns results in the range from -90 to 90 degrees (or the
equivalent range in radians).  Suppose you had data that you
believed to represent roughly three oscillations of a sine wave,
so that the argument of the sine might go from zero to 3*360 degrees.
The above model would appear to be a good way to determine the
true frequency and phase of the sine wave, but in practice it
would fail utterly.  The righthand side of the actual model
`arcsin(y) = a t + b' will grow smoothly with `t', but
the lefthand side will bounce back and forth between -90 and 90.
No values of `a' and `b' can make the two sides match,
even approximately.

There is no good solution to this problem at present.  You could
restrict your data to small enough ranges so that the above problem
doesn't occur (i.e., not straddling any peaks in the sine wave).
Or, in this case, you could use a totally different method such as
Fourier analysis, which is beyond the scope of the `a F' command.
(Unfortunately, Calc does not currently have any facilities for
taking Fourier and related transforms.)


File: calc.info  Node: Curve Fitting Details, Prev: Standard Nonlinear Models, Up: Curve Fitting, Next: Interpolation

Curve Fitting Details
---------------------

Calc's internal least-squares fitter can only handle multilinear
models.  More precisely, it can handle any model of the form
`a f(x,y,z) + b g(x,y,z) + c h(x,y,z)', where `a,b,c'
are the parameters and `x,y,z' are the independent variables
(of course there can be any number of each, not just three).

In a simple multilinear or polynomial fit, it is easy to see how
to convert the model into this form.  For example, if the model
is `a + b x + c x^2', then `f(x) = 1', `g(x) = x',
and `h(x) = x^2' are suitable functions.

For other models, Calc uses a variety of algebraic manipulations
to try to put the problem into the form

     Y(x,y,z) = A(a,b,c) F(x,y,z) + B(a,b,c) G(x,y,z) + C(a,b,c) H(x,y,z)

where `Y,A,B,C,F,G,H' are arbitrary functions.  It computes
`Y', `F', `G', and `H' for all the data points,
does a standard linear fit to find the values of `A', `B',
and `C', then uses the equation solver to solve for `a,b,c'
in terms of `A,B,C'.

A remarkable number of models can be cast into this general form.
We'll look at two examples here to see how it works.  The power-law
model `y = a x^b' with two independent variables and two parameters
can be rewritten as follows:

     y = a x^b
     y = a exp(b ln(x))
     y = exp(ln(a) + b ln(x))
     ln(y) = ln(a) + b ln(x)

which matches the desired form with `Y = ln(y)', `A = ln(a)',
`F = 1', `B = b', and `G = ln(x)'.  Calc thus computes
the logarithms of your `y' and `x' values, does a linear fit
for `A' and `B', then solves to get `a = exp(A)' and
`b = B'.

Another interesting example is the "quadratic" model, which can
be handled by expanding according to the distributive law.

     y = a + b*(x - c)^2
     y = a + b c^2 - 2 b c x + b x^2

which matches with `Y = y', `A = a + b c^2', `F = 1',
`B = -2 b c', `G = x' (the -2 factor could just as easily
have been put into `G' instead of `B'), `C = b', and
`H = x^2'.

The Gaussian model looks quite complicated, but a closer examination
shows that it's actually similar to the quadratic model but with an
exponential that can be brought to the top and moved into `Y'.

An example of a model that cannot be put into general linear
form is a Gaussian with a constant background added on, i.e.,
`d' + the regular Gaussian formula.  If you have a model like
this, your best bet is to replace enough of your parameters with
constants to make the model linearizable, then adjust the constants
manually by doing a series of fits.  You can compare the fits by
graphing them, by examining the goodness-of-fit measures returned by
`I a F', or by some other method suitable to your application.
Note that some models can be linearized in several ways.  The
Gaussian-plus-d model can be linearized by setting `d'
(the background) to a constant, or by setting `b' (the standard
deviation) and `c' (the mean) to constants.

To fit a model with constants substituted for some parameters, just
store suitable values in those parameter variables, then omit them
from the list of parameters when you answer the variables prompt.


A last desperate step would be to use the general-purpose
`minimize' function rather than `fit'.  After all, both
functions solve the problem of minimizing an expression (the `chi^2'
sum) by adjusting certain parameters in the expression.  The `a F'
command is able to use a vastly more efficient algorithm due to its
special knowledge about linear chi-square sums, but the `a N'
command can do the same thing by brute force.

A compromise would be to pick out a few parameters without which the
fit is linearizable, and use `minimize' on a call to `fit'
which efficiently takes care of the rest of the parameters.  The thing
to be minimized would be the value of `chi^2' returned as
the fifth result of the `xfit' function:

     minimize(xfit(gaus(a,b,c,d,x), x, [a,b,c], data)_5, d, guess)

where `gaus' represents the Gaussian model with background,
`data' represents the data matrix, and `guess' represents
the initial guess for `d' that `minimize' requires.
This operation will only be, shall we say, extraordinarily slow
rather than astronomically slow (as would be the case if `minimize'
were used by itself to solve the problem).


The `I a F' [`xfit'] command is somewhat trickier when
nonlinear models are used.  The second item in the result is the
vector of "raw" parameters `A', `B', `C'.  The
covariance matrix is written in terms of those raw parameters.
The fifth item is a vector of "filter" expressions.  This
is the empty vector `[]' if the raw parameters were the same
as the requested parameters, i.e., if `A = a', `B = b',
and so on (which is always possible if the model is already linear
in the parameters as written, e.g., for polynomial fits).  If the
parameters had to be rearranged, the fifth item is instead a vector
of one formula per parameter in the original model.  The raw
parameters are expressed in these "filter" formulas as
`fitdummy(1)' for `A', `fitdummy(2)' for `B',
and so on.

When Calc needs to modify the model to return the result, it replaces
`fitdummy(1)' in all the filters with the first item in the raw
parameters list, and so on for the other raw parameters, then
evaluates the resulting filter formulas to get the actual parameter
values to be substituted into the original model.  In the case of
`H a F' and `I a F' where the parameters must be error forms,
Calc uses the square roots of the diagonal entries of the covariance
matrix as error values for the raw parameters, then lets Calc's
standard error-form arithmetic take it from there.

If you use `I a F' with a nonlinear model, be sure to remember
that the covariance matrix is in terms of the raw parameters,
*not* the actual requested parameters.  It's up to you to
figure out how to interpret the covariances in the presence of
nontrivial filter functions.

Things are also complicated when the input contains error forms.
Suppose there are three independent and dependent variables, `x',
`y', and `z', one or more of which are error forms in the
data.  Calc combines all the error values by taking the square root
of the sum of the squares of the errors.  It then changes `x'
and `y' to be plain numbers, and makes `z' into an error
form with this combined error.  The `Y(x,y,z)' part of the
linearized model is evaluated, and the result should be an error
form.  The error part of that result is used for `sigma_i' for
the data point.  If for some reason `Y(x,y,z)' does not return
an error form, the combined error from `z' is used directly
for `sigma_i'.  Finally, `z' is also stripped of its error
for use in computing `F(x,y,z)', `G(x,y,z)' and so on;
the righthand side of the linearized model is computed in regular
arithmetic with no error forms.

(While these rules may seem complicated, they are designed to do
the most reasonable thing in the typical case that `Y(x,y,z)'
depends only on the dependent variable `z', and in fact is
often simply equal to `z'.  For common cases like polynomials
and multilinear models, the combined error is simply used as the
`sigma' for the data point with no further ado.)


It may be the case that the model you wish to use is linearizable,
but Calc's built-in rules are unable to figure it out.  Calc uses
its algebraic rewrite mechanism to linearize a model.  The rewrite
rules are kept in the variable `FitRules'.  You can edit this
variable using the `s e FitRules' command; in fact, there is
a special `s F' command just for editing `FitRules'.
*Note Operations on Variables::.

*Note Rewrite Rules::, for a discussion of rewrite rules.

Calc uses `FitRules' as follows.  First, it converts the model
to an equation if necessary and encloses the model equation in a
call to the function `fitmodel' (which is not actually defined
by Calc; it is only used as a placeholder by the rewrite rules).
Parameter variables are renamed to function calls `fitparam(1)',
`fitparam(2)', and so on, and independent variables are renamed
to `fitvar(1)', `fitvar(2)', etc.  The dependent variable
is the highest-numbered `fitvar'.  For example, the power law
model `a x^b' is converted to `y = a x^b', then to

     fitmodel(fitvar(2) = fitparam(1) fitvar(1)^fitparam(2))

Calc then applies the rewrites as if by `C-u 0 a r FitRules'.
(The zero prefix means that rewriting should continue until no further
changes are possible.)

When rewriting is complete, the `fitmodel' call should have
been replaced by a `fitsystem' call that looks like this:

     fitsystem(Y, FGH, ABC)

where Y is a formula that describes the function `Y(x,y,z)',
FGH is the vector of formulas `[F(x,y,z), G(x,y,z), H(x,y,z)]',
and ABC is the vector of parameter filters which refer to the
raw parameters as `fitdummy(1)' for `A', `fitdummy(2)'
for `B', etc.  While the number of raw parameters (the length of
the FGH vector) is usually the same as the number of original
parameters (the length of the ABC vector), this is not required.

The power law model eventually boils down to

     fitsystem(ln(fitvar(2)),
               [1, ln(fitvar(1))],
               [exp(fitdummy(1)), fitdummy(2)])

The actual implementation of `FitRules' is complicated; it
proceeds in four phases.  First, common rearrangements are done
to try to bring linear terms together and isolate functions like
`exp' and `ln' either all the way "out" (so that they
can be put into Y) or all the way "in" (so that they can
be put into ABC or FGH).  In particular, all
non-constant powers are converted to logs-and-exponentials form,
and the distributive law is used to expand products of sums.
Quotients are rewritten to use the `fitinv' function, where
`fitinv(x)' represents `1/x' while the `FitRules'
are operating.  (The use of `fitinv' makes recognition of
linear-looking forms easier.)  If you modify `FitRules', you
will probably only need to modify the rules for this phase.

Phase two, whose rules can actually also apply during phases one
and three, first rewrites `fitmodel' to a two-argument
form `fitmodel(Y, MODEL)', where Y is
initially zero and MODEL has been changed from `a=b'
to `a-b' form.  It then tries to peel off invertible functions
from the outside of MODEL and put them into Y instead,
calling the equation solver to invert the functions.  Finally, when
this is no longer possible, the `fitmodel' is changed to a
four-argument `fitsystem', where the fourth argument is
MODEL and the FGH and ABC vectors are initially
empty.  (The last vector is really ABC, corresponding to
raw parameters, for now.)

Phase three converts a sum of items in the MODEL to a sum
of `fitpart(A, B, C)' terms which represent
terms `A*B*C' of the sum, where A
is all factors that do not involve any variables, B is all
factors that involve only parameters, and C is the factors
that involve only independent variables.  (If this decomposition
is not possible, the rule set will not complete and Calc will
complain that the model is too complex.)  Then `fitpart's
with equal B or C components are merged back together
using the distributive law in order to minimize the number of
raw parameters needed.

Phase four moves the `fitpart' terms into the FGH and
ABC vectors.  Also, some of the algebraic expansions that
were done in phase 1 are undone now to make the formulas more
computationally efficient.  Finally, it calls the solver one more
time to convert the ABC vector to an ABC vector, and
removes the fourth MODEL argument (which by now will be zero)
to obtain the three-argument `fitsystem' that the linear
least-squares solver wants to see.

Two functions which are useful in connection with `FitRules'
are `hasfitparams(x)' and `hasfitvars(x)', which check
whether `x' refers to any parameters or independent variables,
respectively.  Specifically, these functions return "true" if the
argument contains any `fitparam' (or `fitvar') function
calls, and "false" otherwise.  (Recall that "true" means a
nonzero number, and "false" means zero.  The actual nonzero number
returned is the largest N from all the `fitparam(N)'s
or `fitvar(N)'s, respectively, that appear in the formula.)


The `fit' function in algebraic notation normally takes four
arguments, `fit(MODEL, VARS, PARAMS, DATA)',
where MODEL is the model formula as it would be typed after
`a F '', VARS is the independent variable or a vector of
independent variables, PARAMS likewise gives the parameter(s),
and DATA is the data matrix.  Note that the length of VARS
must be equal to the number of rows in DATA if MODEL is
an equation, or one less than the number of rows if MODEL is
a plain formula.  (Actually, a name for the dependent variable is
allowed but will be ignored in the plain-formula case.)

If PARAMS is omitted, the parameters are all variables in
MODEL except those that appear in VARS.  If VARS
is also omitted, Calc sorts all the variables that appear in
MODEL alphabetically and uses the higher ones for VARS
and the lower ones for PARAMS.

Alternatively, `fit(MODELVEC, DATA)' is allowed
where MODELVEC is a 2- or 3-vector describing the model
and variables, as discussed previously.

If Calc is unable to do the fit, the `fit' function is left
in symbolic form, ordinarily with an explanatory message.  The
message will be "Model expression is too complex" if the
linearizer was unable to put the model into the required form.

The `efit' (corresponding to `H a F') and `xfit'
(for `I a F') functions are completely analogous.


File: calc.info  Node: Interpolation, Prev: Curve Fitting Details, Up: Curve Fitting

Polynomial Interpolation
------------------------

The `a p' (`calc-poly-interp') [`polint'] command does
a polynomial interpolation at a particular `x' value.  It takes
two arguments from the stack:  A data matrix of the sort used by
`a F', and a single number which represents the desired `x'
value.  Calc effectively does an exact polynomial fit as if by `a F i',
then substitutes the `x' value into the result in order to get an
approximate `y' value based on the fit.  (Calc does not actually
use `a F i', however; it uses a direct method which is both more
efficient and more numerically stable.)

The result of `a p' is actually a vector of two values:  The `y'
value approximation, and an error measure `dy' that reflects Calc's
estimation of the probable error of the approximation at that value of
`x'.  If the input `x' is equal to any of the `x' values
in the data matrix, the output `y' will be the corresponding `y'
value from the matrix, and the output `dy' will be exactly zero.

A prefix argument of 2 causes `a p' to take two vectors (`x'
and `y') from the stack instead of one data matrix.

If `x' is a vector of numbers, `a p' will return a matrix of
interpolated results for each of those `x' values.  (The matrix will
have two columns, the `y' values and the `dy' values.)
If `x' is a formula instead of a number, the `polint' function
remains in symbolic form; use the `a "' command to expand it out to
a formula that describes the fit in symbolic terms.

In all cases, the `a p' command leaves the data vectors or matrix
on the stack.  Only the `x' value is replaced by the result.

The `H a p' [`ratint'] command does a rational function
interpolation.  It is used exactly like `a p', except that it
uses as its model the quotient of two polynomials.  If there are
`N' data points, the numerator and denominator polynomials will
each have degree `N/2' (if `N' is odd, the denominator will
have degree one higher than the numerator).

Rational approximations have the advantage that they can accurately
describe functions that have poles (points at which the function's value
goes to infinity, so that the denominator polynomial of the approximation
goes to zero).  If `x' corresponds to a pole of the fitted rational
function, then the result will be a division by zero.  If Infinite mode
is enabled, the result will be `[uinf, uinf]'.

There is no way to get the actual coefficients of the rational function
used by `H a p'.  (The algorithm never generates these coefficients
explicitly, and quotients of polynomials are beyond `a F''s
capabilities to fit.)


File: calc.info  Node: Summations, Prev: Curve Fitting, Up: Algebra, Next: Logical Operations

Summations
==========

The `a +' (`calc-summation') [`sum'] command computes
the sum of a formula over a certain range of indices.  The formula
is taken from the top of the stack; the command prompts for the
name of the summation index variable, the lower limit of the
sum (any formula), and the upper limit of the sum.  If you
enter a blank line at any of these prompts, that prompt and
any later ones are answered by reading additional elements from
the stack.  Thus, `' k^2 RET ' k RET 1 RET 5 RET a + RET'
produces the result 55.

The choice of index variable is arbitrary, but it's best not to
use a variable with a stored value.  In particular, while
`i' is often a favorite index variable, it should be avoided
in Calc because `i' has the imaginary constant `(0, 1)'
as a value.  If you pressed `=' on a sum over `i', it would
be changed to a nonsensical sum over the "variable" `(0, 1)'!
If you really want to use `i' as an index variable, use
`s u i RET' first to "unstore" this variable.
(*Note Storing Variables::.)

A numeric prefix argument steps the index by that amount rather
than by one.  Thus `' a_k RET C-u -2 a + k RET 10 RET 0 RET'
yields `a_10 + a_8 + a_6 + a_4 + a_2 + a_0'.  A prefix
argument of plain `C-u' causes `a +' to prompt for the
step value, in which case you can enter any formula or enter
a blank line to take the step value from the stack.  With the
`C-u' prefix, `a +' can take up to five arguments from
the stack:  The formula, the variable, the lower limit, the
upper limit, and (at the top of the stack), the step value.

Calc knows how to do certain sums in closed form.  For example,
`sum(6 k^2, k, 1, n) = 2 n^3 + 3 n^2 + n'.  In particular,
this is possible if the formula being summed is polynomial or
exponential in the index variable.  Sums of logarithms are
transformed into logarithms of products.  Sums of trigonometric
and hyperbolic functions are transformed to sums of exponentials
and then done in closed form.  Also, of course, sums in which the
lower and upper limits are both numbers can always be evaluated
just by grinding them out, although Calc will use closed forms
whenever it can for the sake of efficiency.

The notation for sums in algebraic formulas is
`sum(EXPR, VAR, LOW, HIGH, STEP)'.
If STEP is omitted, it defaults to one.  If HIGH is
omitted, LOW is actually the upper limit and the lower limit
is one.  If LOW is also omitted, the limits are `-inf'
and `inf', respectively.

Infinite sums can sometimes be evaluated:  `sum(.5^k, k, 1, inf)'
returns `1'.  This is done by evaluating the sum in closed
form (to `1. - 0.5^n' in this case), then evaluating this
formula with `n' set to `inf'.  Calc's usual rules
for "infinite" arithmetic can find the answer from here.  If
infinite arithmetic yields a `nan', or if the sum cannot be
solved in closed form, Calc leaves the `sum' function in
symbolic form.  *Note Infinities::.

As a special feature, if the limits are infinite (or omitted, as
described above) but the formula includes vectors subscripted by
expressions that include the iteration variable, Calc narrows
the limits to include only the range of integers which result in
legal subscripts for the vector.  For example, the sum
`sum(k [a,b,c,d,e,f,g]_(2k),k)' evaluates to `b + 2 d + 3 f'.

The limits of a sum do not need to be integers.  For example,
`sum(a_k, k, 0, 2 n, n)' produces `a_0 + a_n + a_(2 n)'.
Calc computes the number of iterations using the formula
`1 + (HIGH - LOW) / STEP', which must,
after simplification as if by `a s', evaluate to an integer.

If the number of iterations according to the above formula does
not come out to an integer, the sum is illegal and will be left
in symbolic form.  However, closed forms are still supplied, and
you are on your honor not to misuse the resulting formulas by
substituting mismatched bounds into them.  For example,
`sum(k, k, 1, 10, 2)' is invalid, but Calc will go ahead and
evaluate the closed form solution for the limits 1 and 10 to get
the rather dubious answer, 29.25.

If the lower limit is greater than the upper limit (assuming a
positive step size), the result is generally zero.  However,
Calc only guarantees a zero result when the upper limit is
exactly one step less than the lower limit, i.e., if the number
of iterations is -1.  Thus `sum(f(k), k, n, n-1)' is zero
but the sum from `n' to `n-2' may report a nonzero value
if closed form solutions were used.

Calc's logical predicates like `a < b' return 1 for "true"
and 0 for "false."  *Note Logical Operations::.  This can be
used to advantage for building conditional sums.  For example,
`sum(prime(k)*k^2, k, 1, 20)' is the sum of the squares of all
prime numbers from 1 to 20; the `prime' predicate returns 1 if
its argument is prime and 0 otherwise.  You can read this expression
as "the sum of `k^2', where `k' is prime."  Indeed,
`sum(prime(k)*k^2, k)' would represent the sum of *all* primes
squared, since the limits default to plus and minus infinity, but
there are no such sums that Calc's built-in rules can write in
closed form.

As another example, `sum((k != k_0) * f(k), k, 1, n)' is the
sum of `f(k)' for all `k' from 1 to `n', excluding
one value `k_0'.  Slightly more tricky is the summand
`(k != k_0) / (k - k_0)', which is an attempt to describe
the sum of all `1/(k-k_0)' except at `k = k_0', where
this would be a division by zero.  But at `k = k_0', this
formula works out to the indeterminate form `0 / 0', which
Calc will not assume is zero.  Better would be to use
`(k != k_0) ? 1/(k-k_0) : 0'; the `? :' operator does
an "if-then-else" test:  This expression says, "if `k != k_0',
then `1/(k-k_0)', else zero."  Now the formula `1/(k-k_0)'
will not even be evaluated by Calc when `k = k_0'.

The `a -' (`calc-alt-summation') [`asum'] command
computes an alternating sum.  Successive terms of the sequence
are given alternating signs, with the first term (corresponding
to the lower index value) being positive.  Alternating sums
are converted to normal sums with an extra term of the form
`(-1)^(k-LOW)'.  This formula is adjusted appropriately
if the step value is other than one.  For example, the Taylor
series for the sine function is `asum(x^k / k!, k, 1, inf, 2)'.
(Calc cannot evaluate this infinite series, but it can approximate
it if you replace `inf' with any particular odd number.)
Calc converts this series to a regular sum with a step of one,
namely `sum((-1)^k x^(2k+1) / (2k+1)!, k, 0, inf)'.

The `a *' (`calc-product') [`prod'] command is
the analogous way to take a product of many terms.  Calc also knows
some closed forms for products, such as `prod(k, k, 1, n) = n!'.
Conditional products can be written, e.g., `prod(k^prime(k), k, 1, n)'
or `prod(prime(k) ? k : 1, k, 1, n)'.

The `a T' (`calc-tabulate') [`table'] command
evaluates a formula at a series of iterated index values, just
like `sum' and `prod', but its result is simply a
vector of the results.  For example, `table(a_i, i, 1, 7, 2)'
produces `[a_1, a_3, a_5, a_7]'.


